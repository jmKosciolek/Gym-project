{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a4a2328e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re # Used for regular expressions in parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33bbf63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. Data Ingestion ---\n",
    "# Read the raw workout data from two separate text files.\n",
    "# .strip() removes leading/trailing whitespace, and `if line.strip()` ignores empty lines.\n",
    "with open('Data/Strong.txt', 'r', encoding='utf-8') as f1, open('Data/strongv6.txt', 'r', encoding='utf-8') as f2:\n",
    "    strong_lines = [line.strip() for line in f1 if line.strip()]\n",
    "    strongv6_lines = [line.strip() for line in f2 if line.strip()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5617ef64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Helper Function: Group Lines by Date ---\n",
    "# This function groups the raw text lines into sublists, where each sublist\n",
    "# represents a single workout session, starting with a date.\n",
    "def group_by_date(lines):\n",
    "    grouped = [] # List to hold all workout groups\n",
    "    current = [] # List to hold lines for the current workout\n",
    "    for line in lines:\n",
    "        # If a line starts with a digit, it's assumed to be a new date,\n",
    "        # indicating the start of a new workout session.\n",
    "        if line and line[0].isdigit():\n",
    "            if current: # If 'current' is not empty, it means a previous workout group is complete\n",
    "                grouped.append(current) # Add the completed group to 'grouped'\n",
    "            current = [line] # Start a new group with the current date line\n",
    "        else:\n",
    "            # If the line doesn't start with a digit, it's an exercise entry\n",
    "            # for the current workout, so append it to the 'current' group.\n",
    "            current.append(line)\n",
    "    if current: # Add the last collected group if it's not empty\n",
    "        grouped.append(current)\n",
    "    return grouped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fe68b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the grouping function to both sets of raw lines\n",
    "strong_lines_grouped = group_by_date(strong_lines)\n",
    "strongv6_lines_grouped = group_by_date(strongv6_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f066e3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Helper Function: Parse Exercise Lines ---\n",
    "# This function takes a single exercise line (e.g., 'Bench 50kgx12 55kgx10')\n",
    "# and parses it into a structured format (list of dictionaries).\n",
    "def parse_exercise_line(line):\n",
    "    \"\"\"\n",
    "    Parses lines like:\n",
    "    - 'Bench 50kgx12 55kgx10 60kgx9'\n",
    "    - 'Squads 80kgx8x8'\n",
    "    - 'Pull ups 10x8x8' (where weight is implied/bodyweight, so 0kg or None)\n",
    "    into a list of dictionaries with 'exercise', 'weight', 'reps', and 'order' (set number).\n",
    "    \"\"\"\n",
    "    parts = line.split()\n",
    "    if not parts: # Handle empty lines that might slip through\n",
    "        return []\n",
    "\n",
    "    exercise_name_parts = []\n",
    "    sets_data_parts = []\n",
    "    \n",
    "    # Separate exercise name from sets data\n",
    "    # Iterate through parts to find where the weight/reps pattern starts\n",
    "    found_sets_start = False\n",
    "    for part in parts:\n",
    "        if re.match(r'(\\d+kgx\\d+.*)|(\\d+x\\d+.*)', part): # Check for weightxreps or repsxreps pattern\n",
    "            found_sets_start = True\n",
    "        if not found_sets_start:\n",
    "            exercise_name_parts.append(part)\n",
    "        else:\n",
    "            sets_data_parts.append(part)\n",
    "            \n",
    "    exercise = ' '.join(exercise_name_parts) # Reconstruct exercise name (e.g., 'Pull ups')\n",
    "    \n",
    "    results = []\n",
    "    order = 1 # Initialize set order for each exercise within a workout\n",
    "    \n",
    "    for s in sets_data_parts:\n",
    "        # Pattern 1: Matches 'WEIGHTkgxREPS' or 'WEIGHTkgxREPSxREPS...'\n",
    "        m_kg = re.match(r'(\\d+)kgx(\\d+(?:x\\d+)*)', s)\n",
    "        if m_kg:\n",
    "            weight = int(m_kg.group(1))\n",
    "            reps_list = list(map(int, m_kg.group(2).split('x')))\n",
    "            for reps in reps_list:\n",
    "                results.append({'exercise': exercise, 'weight': weight, 'reps': reps, 'order': order})\n",
    "                order += 1\n",
    "        else:\n",
    "            # Pattern 2: Matches 'REPSxREPS...' (e.g., for bodyweight exercises like Pull-ups)\n",
    "            # This assumes if 'kg' is not present, weight is 0 or None.\n",
    "            m_reps_only = re.match(r'(\\d+(?:x\\d+)*)', s)\n",
    "            if m_reps_only:\n",
    "                reps_list = list(map(int, m_reps_only.group(1).split('x')))\n",
    "                for reps in reps_list:\n",
    "                    # Assign weight as 0 for bodyweight exercises or when not specified\n",
    "                    results.append({'exercise': exercise, 'weight': 0, 'reps': reps, 'order': order})\n",
    "                    order += 1\n",
    "            else:\n",
    "                # Fallback for any unhandled patterns, or single numbers (e.g., '10' for 10 reps)\n",
    "                # This might need refinement based on actual data variations\n",
    "                try:\n",
    "                    reps_val = int(s)\n",
    "                    results.append({'exercise': exercise, 'weight': 0, 'reps': reps_val, 'order': order})\n",
    "                    order += 1\n",
    "                except ValueError:\n",
    "                    # If parsing fails, skip or log an error\n",
    "                    print(f\"Warning: Could not parse part '{s}' in line '{line}'\")\n",
    "                    continue\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "786a7972",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Pull-ups', 'Deadlifts', 'Bench', 'Knee', 'Squads',\n",
       "       'Underhand Barbell Row', 'Overhead Press', 'Bulgarian Squads',\n",
       "       'Leg Raises', 'Dips'], dtype=object)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --- 4. Helper Function: Create DataFrame from Grouped Lines ---\n",
    "# This function iterates through the grouped workout data and creates a Pandas DataFrame.\n",
    "def create_dataframe(grouped_lines):\n",
    "    rows = []\n",
    "    for group in grouped_lines:\n",
    "        date_str = group[0] # The first line of each group is the date\n",
    "        # Attempt to parse date, assuming DD.MM.YYYY format\n",
    "        try:\n",
    "            # If year is missing (e.g., '17.11'), assume current year or the year the data was collected for\n",
    "            # For this project, as per the example, it seems to be 2024.\n",
    "            # A more robust solution would infer the year or require it in input.\n",
    "            if len(date_str.split('.')) == 2: # e.g., '17.11'\n",
    "                date = pd.to_datetime(date_str + '.2024', format=\"%d.%m.%Y\")\n",
    "            else: # e.g., '13.11.2024'\n",
    "                date = pd.to_datetime(date_str, format=\"%d.%m.%Y\")\n",
    "        except ValueError:\n",
    "            print(f\"Warning: Could not parse date '{date_str}'. Skipping group.\")\n",
    "            continue\n",
    "\n",
    "        for line in group[1:]: # Iterate through exercise lines in the group\n",
    "            for entry in parse_exercise_line(line):\n",
    "                rows.append({'Date': date, **entry}) # Add date to each parsed exercise entry\n",
    "    \n",
    "    df = pd.DataFrame(rows)\n",
    "    # Rename columns for clarity and consistency with Power BI\n",
    "    df.columns = ['Date', 'Exercise', 'Weight (kg)', 'Reps', 'Order']\n",
    "    return df\n",
    "\n",
    "# Create DataFrames for both strong.txt and strongv6.txt\n",
    "df_strong = create_dataframe(strong_lines_grouped)\n",
    "df_strongv6 = create_dataframe(strongv6_lines_grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87255c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 5. Data Cleaning and Normalization (Exercise Names) ---\n",
    "# Define a mapping for inconsistent exercise names to a standardized format.\n",
    "exercise_name_mapping = {\n",
    "    'Pull': 'Pull-ups',\n",
    "    'pull': 'Pull-ups',\n",
    "    'Pull-up': 'Pull-ups',\n",
    "    'Dipy': 'Dips',\n",
    "    'Squars': 'Squads',\n",
    "    'Squats': 'Squads', # Standardize to 'Squads' as per your original notebook\n",
    "    'Deadlift': 'Deadlifts',\n",
    "    'Bulgarian': 'Bulgarian Squads',\n",
    "    'Leg': 'Leg Raises',\n",
    "    'Overhead': 'Overhead Press',\n",
    "    'Underhand': 'Underhand Barbell Row',\n",
    "    'Overhand': 'Overhead Press', # Correcting potential typo for Overhead Press\n",
    "    'Knee': 'Leg Raises', # Assuming 'Knee' refers to Leg Raises as per original notebook\n",
    "    'Kółko': 'Wheel', # Assuming 'Kółko' refers to 'Wheel'\n",
    "    'Barbell': 'Barbell Row' # Assuming 'Barbell' refers to Barbell Row\n",
    "}\n",
    "\n",
    "# Apply normalization to both DataFrames\n",
    "df_strong['Exercise'] = df_strong['Exercise'].replace(exercise_name_mapping)\n",
    "df_strongv6['Exercise'] = df_strongv6['Exercise'].replace(exercise_name_mapping)\n",
    "\n",
    "# Handle cases where weight might be None (e.g., for bodyweight exercises)\n",
    "# Replace None/NaN in 'Weight (kg)' with 0 for numerical calculations.\n",
    "df_strong['Weight (kg)'] = df_strong['Weight (kg)'].fillna(0)\n",
    "df_strongv6['Weight (kg)'] = df_strongv6['Weight (kg)'].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf50ef8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 6. Concatenate DataFrames ---\n",
    "# Combine the two cleaned DataFrames into a single, comprehensive DataFrame.\n",
    "# ignore_index=True ensures the new DataFrame has a continuous index.\n",
    "big_strong = pd.concat([df_strong, df_strongv6], ignore_index=True)\n",
    "\n",
    "# Display unique exercise names after full normalization to verify\n",
    "print(\"Unique Exercise Names after full normalization:\")\n",
    "print(big_strong['Exercise'].unique())\n",
    "print(\"-\" * 80)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ba0c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 7. Save Combined Data to Excel ---\n",
    "# This Excel file will be the input for Power BI.\n",
    "big_strong.to_excel('big_strong.xlsx', index=False)\n",
    "print(\"Combined and cleaned data saved to 'big_strong.xlsx'\")\n",
    "print(\"-\" * 80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DataScrapeProject",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
